{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5fbdb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85b5d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "\n",
    "data = {\n",
    "    'customer_id': range(1, n_samples + 1),\n",
    "    'age': np.random.randint(18, 80, n_samples),\n",
    "    'income': np.random.normal(50000, 20000, n_samples),\n",
    "    'account_balance': np.random.normal(5000, 3000, n_samples),\n",
    "    'tenure_months': np.random.randint(1, 120, n_samples),\n",
    "    'num_products': np.random.randint(1, 5, n_samples),\n",
    "    'credit_score': np.random.randint(300, 850, n_samples),\n",
    "    'gender': np.random.choice(['Male', 'Female', 'Other'], n_samples),\n",
    "    'location': np.random.choice(['Urban', 'Suburban', 'Rural'], n_samples),\n",
    "    'customer_service_calls': np.random.randint(0, 10, n_samples),\n",
    "    'churned': np.random.choice([0, 1], n_samples, p=[0.7, 0.3])\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f86a4064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset created with 1005 rows and 11 columns\n",
      "\n",
      "First few rows:\n",
      "   customer_id   age        income  account_balance  tenure_months  \\\n",
      "0            1  56.0  77447.555931      4737.085227              9   \n",
      "1            2  69.0  36444.278140      5458.153698             36   \n",
      "2            3  46.0  73070.637440      6764.599805             83   \n",
      "3            4  32.0  42499.787433      6526.004749              1   \n",
      "4            5  60.0  36117.080930     -2295.140714             10   \n",
      "\n",
      "   num_products  credit_score  gender  location  customer_service_calls  \\\n",
      "0             1         699.0    Male     Rural                       6   \n",
      "1             2         751.0  Female  Suburban                       6   \n",
      "2             4         403.0    Male  Suburban                       3   \n",
      "3             1         761.0   Other     Rural                       8   \n",
      "4             1         695.0  Female     Urban                       7   \n",
      "\n",
      "   churned  \n",
      "0        0  \n",
      "1        0  \n",
      "2        1  \n",
      "3        0  \n",
      "4        1  \n"
     ]
    }
   ],
   "source": [
    "# Introduce data quality issues\n",
    "# 1. Missing values\n",
    "df.loc[np.random.choice(df.index, 50), 'age'] = np.nan\n",
    "df.loc[np.random.choice(df.index, 80), 'income'] = np.nan\n",
    "df.loc[np.random.choice(df.index, 30), 'credit_score'] = np.nan\n",
    "df.loc[np.random.choice(df.index, 20), 'gender'] = np.nan\n",
    "\n",
    "# 2. Outliers\n",
    "df.loc[np.random.choice(df.index, 10), 'income'] = np.random.uniform(200000, 500000, 10)\n",
    "df.loc[np.random.choice(df.index, 5), 'account_balance'] = np.random.uniform(-10000, -5000, 5)\n",
    "\n",
    "# 3. Inconsistent data\n",
    "df.loc[np.random.choice(df.index, 10), 'gender'] = df.loc[np.random.choice(df.index, 10), 'gender'].str.lower()\n",
    "\n",
    "# 4. Duplicates\n",
    "duplicate_rows = df.sample(5)\n",
    "df = pd.concat([df, duplicate_rows], ignore_index=True)\n",
    "\n",
    "print(f\"\\nDataset created with {len(df)} rows and {len(df.columns)} columns\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9c55217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1005 entries, 0 to 1004\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   customer_id             1005 non-null   int64  \n",
      " 1   age                     956 non-null    float64\n",
      " 2   income                  927 non-null    float64\n",
      " 3   account_balance         1005 non-null   float64\n",
      " 4   tenure_months           1005 non-null   int64  \n",
      " 5   num_products            1005 non-null   int64  \n",
      " 6   credit_score            977 non-null    float64\n",
      " 7   gender                  974 non-null    object \n",
      " 8   location                1005 non-null   object \n",
      " 9   customer_service_calls  1005 non-null   int64  \n",
      " 10  churned                 1005 non-null   int64  \n",
      "dtypes: float64(4), int64(5), object(2)\n",
      "memory usage: 86.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1985e943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd2a0436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'age', 'income', 'account_balance', 'tenure_months',\n",
       "       'num_products', 'credit_score', 'gender', 'location',\n",
       "       'customer_service_calls', 'churned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a25fb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>account_balance</th>\n",
       "      <th>tenure_months</th>\n",
       "      <th>num_products</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>customer_service_calls</th>\n",
       "      <th>churned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1005.000000</td>\n",
       "      <td>956.00000</td>\n",
       "      <td>927.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>977.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>500.976119</td>\n",
       "      <td>50.08682</td>\n",
       "      <td>54186.821944</td>\n",
       "      <td>5074.146555</td>\n",
       "      <td>59.973134</td>\n",
       "      <td>2.536318</td>\n",
       "      <td>578.943705</td>\n",
       "      <td>4.555224</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>289.239395</td>\n",
       "      <td>18.12400</td>\n",
       "      <td>39006.384482</td>\n",
       "      <td>3169.170188</td>\n",
       "      <td>33.712286</td>\n",
       "      <td>1.118446</td>\n",
       "      <td>161.728217</td>\n",
       "      <td>2.958239</td>\n",
       "      <td>0.442437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>-21364.105987</td>\n",
       "      <td>-9867.765487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>37452.705739</td>\n",
       "      <td>3011.645596</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>433.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>501.000000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>51653.119189</td>\n",
       "      <td>5178.658905</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>751.000000</td>\n",
       "      <td>66.00000</td>\n",
       "      <td>65579.159507</td>\n",
       "      <td>7204.680510</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>727.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>79.00000</td>\n",
       "      <td>445063.395768</td>\n",
       "      <td>14763.941879</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>849.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id        age         income  account_balance  tenure_months  \\\n",
       "count  1005.000000  956.00000     927.000000      1005.000000    1005.000000   \n",
       "mean    500.976119   50.08682   54186.821944      5074.146555      59.973134   \n",
       "std     289.239395   18.12400   39006.384482      3169.170188      33.712286   \n",
       "min       1.000000   18.00000  -21364.105987     -9867.765487       1.000000   \n",
       "25%     250.000000   35.00000   37452.705739      3011.645596      32.000000   \n",
       "50%     501.000000   50.00000   51653.119189      5178.658905      59.000000   \n",
       "75%     751.000000   66.00000   65579.159507      7204.680510      88.000000   \n",
       "max    1000.000000   79.00000  445063.395768     14763.941879     119.000000   \n",
       "\n",
       "       num_products  credit_score  customer_service_calls      churned  \n",
       "count   1005.000000    977.000000             1005.000000  1005.000000  \n",
       "mean       2.536318    578.943705                4.555224     0.266667  \n",
       "std        1.118446    161.728217                2.958239     0.442437  \n",
       "min        1.000000    300.000000                0.000000     0.000000  \n",
       "25%        2.000000    433.000000                2.000000     0.000000  \n",
       "50%        3.000000    572.000000                5.000000     0.000000  \n",
       "75%        4.000000    727.000000                7.000000     1.000000  \n",
       "max        4.000000    849.000000                9.000000     1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4db2676a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                 int64\n",
       "age                       float64\n",
       "income                    float64\n",
       "account_balance           float64\n",
       "tenure_months               int64\n",
       "num_products                int64\n",
       "credit_score              float64\n",
       "gender                     object\n",
       "location                   object\n",
       "customer_service_calls      int64\n",
       "churned                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a19156b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing_Count  Percentage\n",
      "income                   78    7.761194\n",
      "age                      49    4.875622\n",
      "gender                   31    3.084577\n",
      "credit_score             28    2.786070\n"
     ]
    }
   ],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing_percent = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "print(missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d37cb207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3.2 Duplicate Rows:\n",
      "Number of duplicate rows: 5\n",
      "\n",
      "Duplicate rows:\n",
      "      customer_id   age         income  account_balance  tenure_months  \\\n",
      "153           154  45.0   62876.052034      7204.680510            113   \n",
      "1002          154  45.0   62876.052034      7204.680510            113   \n",
      "201           202  54.0            NaN      3228.565794              9   \n",
      "1000          202  54.0            NaN      3228.565794              9   \n",
      "732           733  67.0   62360.574220      2987.491890             75   \n",
      "1001          733  67.0   62360.574220      2987.491890             75   \n",
      "924           925  58.0            NaN      4457.718531             89   \n",
      "1004          925  58.0            NaN      4457.718531             89   \n",
      "966           967  50.0  445063.395768       959.712774             72   \n",
      "1003          967  50.0  445063.395768       959.712774             72   \n",
      "\n",
      "      num_products  credit_score gender  location  customer_service_calls  \\\n",
      "153              2         559.0    NaN     Rural                       0   \n",
      "1002             2         559.0    NaN     Rural                       0   \n",
      "201              2         332.0   Male     Rural                       6   \n",
      "1000             2         332.0   Male     Rural                       6   \n",
      "732              3         421.0   Male  Suburban                       8   \n",
      "1001             3         421.0   Male  Suburban                       8   \n",
      "924              1         758.0   Male     Rural                       9   \n",
      "1004             1         758.0   Male     Rural                       9   \n",
      "966              1         368.0   Male     Rural                       2   \n",
      "1003             1         368.0   Male     Rural                       2   \n",
      "\n",
      "      churned  \n",
      "153         0  \n",
      "1002        0  \n",
      "201         0  \n",
      "1000        0  \n",
      "732         0  \n",
      "1001        0  \n",
      "924         1  \n",
      "1004        1  \n",
      "966         0  \n",
      "1003        0  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3.2 Duplicate Rows:\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    print(\"\\nDuplicate rows:\")\n",
    "    print(df[df.duplicated(keep=False)].sort_values('customer_id'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a97cd511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3.3 Unique Values per Column:\n",
      "customer_id: 1000 unique values\n",
      "age: 62 unique values\n",
      "income: 924 unique values\n",
      "account_balance: 1000 unique values\n",
      "tenure_months: 119 unique values\n",
      "num_products: 4 unique values\n",
      "credit_score: 451 unique values\n",
      "gender: 3 unique values\n",
      "location: 3 unique values\n",
      "customer_service_calls: 10 unique values\n",
      "churned: 2 unique values\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3.3 Unique Values per Column:\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b718393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3.4 Value Counts for Categorical Variables:\n",
      "\n",
      "gender:\n",
      "gender\n",
      "Female    335\n",
      "Male      326\n",
      "Other     313\n",
      "Name: count, dtype: int64\n",
      "\n",
      "location:\n",
      "location\n",
      "Suburban    353\n",
      "Rural       333\n",
      "Urban       319\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3.4 Value Counts for Categorical Variables:\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa51cbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4.1 Removing duplicates...\n",
      "Rows after removing duplicates: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4.1 Removing duplicates...\")\n",
    "df_clean = df.drop_duplicates()\n",
    "print(f\"Rows after removing duplicates: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61a03d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4.2 Standardizing categorical values...\n",
      "Gender values after standardization:\n",
      "gender\n",
      "Female    335\n",
      "Male      322\n",
      "Other     313\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4.2 Standardizing categorical values...\")\n",
    "df_clean['gender'] = df_clean['gender'].str.title()\n",
    "print(\"Gender values after standardization:\")\n",
    "print(df_clean['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8a079cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4.3 Handling negative account balances...\n",
      "Rows with negative balance: 0\n"
     ]
    }
   ],
   "source": [
    "# 4.3 Handle negative account balances (domain-specific cleaning)\n",
    "print(\"\\n4.3 Handling negative account balances...\")\n",
    "print(f\"Rows with negative balance: {(df_clean['account_balance'] < 0).sum()}\")\n",
    "df_clean['account_balance'] = df_clean['account_balance'].clip(lower=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b80e4009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 5: EXPLORATORY DATA ANALYSIS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 5: EXPLORATORY DATA ANALYSIS (EDA)\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6fe3250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.1 Target Variable Distribution:\n",
      "churned\n",
      "0    733\n",
      "1    267\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Churn Rate: 26.70%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5.1 Target Variable Distribution:\")\n",
    "print(df_clean['churned'].value_counts())\n",
    "print(f\"\\nChurn Rate: {df_clean['churned'].mean()*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1ffb109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.2 Correlation Analysis:\n",
      "\n",
      "Correlation with target variable 'churned':\n",
      "churned                   1.000000\n",
      "customer_id               0.025860\n",
      "account_balance           0.004023\n",
      "num_products             -0.004407\n",
      "income                   -0.006685\n",
      "tenure_months            -0.017403\n",
      "credit_score             -0.019715\n",
      "customer_service_calls   -0.024986\n",
      "age                      -0.038009\n",
      "Name: churned, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5.2 Correlation Analysis:\")\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df_clean[numeric_cols].corr()\n",
    "print(\"\\nCorrelation with target variable 'churned':\")\n",
    "print(correlation_matrix['churned'].sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51cde1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 6: OUTLIER DETECTION AND HANDLING\n",
      "============================================================\n",
      "\n",
      "age:\n",
      "  Outliers detected: 0\n",
      "  Lower bound: -11.50, Upper bound: 112.50\n",
      "\n",
      "income:\n",
      "  Outliers detected: 17\n",
      "  Lower bound: -4652.42, Upper bound: 107604.89\n",
      "\n",
      "account_balance:\n",
      "  Outliers detected: 3\n",
      "  Lower bound: -3246.96, Upper bound: 13477.90\n",
      "\n",
      "credit_score:\n",
      "  Outliers detected: 0\n",
      "  Lower bound: -8.38, Upper bound: 1168.62\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 6: OUTLIER DETECTION AND HANDLING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Detect outliers in numerical columns\n",
    "numerical_columns = ['age', 'income', 'account_balance', 'credit_score']\n",
    "for col in numerical_columns:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df_clean, col)\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Outliers detected: {len(outliers)}\")\n",
    "    print(f\"  Lower bound: {lower:.2f}, Upper bound: {upper:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18b10633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6.1 Handling outliers using winsorization...\n"
     ]
    }
   ],
   "source": [
    "# Handle outliers by capping (winsorization)\n",
    "print(\"\\n6.1 Handling outliers using winsorization...\")\n",
    "for col in numerical_columns:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5*IQR\n",
    "    upper_bound = Q3 + 1.5*IQR\n",
    "\n",
    "    df_clean[col] = df_clean[col].clip(lower= lower_bound, upper= upper_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82c54ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 7: MISSING VALUE IMPUTATION\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: MISSING VALUE IMPUTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_imputed = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16ae68fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7.1 Imputing numerical variables...\n",
      "Missing values after numerical imputation:\n",
      "age                0\n",
      "income             0\n",
      "account_balance    0\n",
      "credit_score       0\n",
      "dtype: int64\n",
      "\n",
      "7.2 Imputing categorical variables...\n",
      "Missing values after categorical imputation:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Impute numerical variables\n",
    "print(\"\\n7.1 Imputing numerical variables...\")\n",
    "\n",
    "# Mean imputation for age\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed['age'] = mean_imputer.fit_transform(df_imputed[['age']])\n",
    "\n",
    "# Median imputation for income (better for skewed data)\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "df_imputed['income'] = median_imputer.fit_transform(df_imputed[['income']])\n",
    "\n",
    "# KNN imputation for credit_score\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed['credit_score'] = knn_imputer.fit_transform(df_imputed[['credit_score']])\n",
    "\n",
    "print(\"Missing values after numerical imputation:\")\n",
    "print(df_imputed[numerical_columns].isnull().sum())\n",
    "\n",
    "# 7.2 Impute categorical variables\n",
    "print(\"\\n7.2 Imputing categorical variables...\")\n",
    "\n",
    "# Mode imputation for gender\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_imputed['gender'] = mode_imputer.fit_transform(df_imputed[['gender']]).ravel()\n",
    "\n",
    "print(\"Missing values after categorical imputation:\")\n",
    "print(df_imputed['gender'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be37e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id               0\n",
      "age                       0\n",
      "income                    0\n",
      "account_balance           0\n",
      "tenure_months             0\n",
      "num_products              0\n",
      "credit_score              0\n",
      "gender                    0\n",
      "location                  0\n",
      "customer_service_calls    0\n",
      "churned                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n7.3 Final missing value check:\")\n",
    "print (df_imputed.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78109947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 8: FEATURE ENGINEERING\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    " #============================================\n",
    "# STEP 8: FEATURE ENGINEERING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 8: FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cb74413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create age groups\n",
    "df_imputed['age_group'] = pd.cut(df_imputed['age'], \n",
    "                                  bins=[0, 30, 50, 70, 100], \n",
    "                                  labels=['Young', 'Middle', 'Senior', 'Elderly'])\n",
    "\n",
    "df_imputed['income_bracket'] = pd.cut(df_imputed['income'], \n",
    "                                       bins=[0, 30000, 60000, 100000, np.inf], \n",
    "                                       labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Create balance to income ratio\n",
    "df_imputed['balance_to_income_ratio'] = df_imputed['account_balance'] / (df_imputed['income'] + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76e90892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New features created:\n",
      "  age_group income_bracket  balance_to_income_ratio  customer_value_score\n",
      "0    Senior           High                 0.061164             70.070852\n",
      "1    Senior         Medium                 0.149763            105.381537\n",
      "2    Middle           High                 0.092575            172.545998\n",
      "3    Middle         Medium                 0.153550             85.560047\n",
      "4    Senior         Medium                 0.000000             23.000000\n"
     ]
    }
   ],
   "source": [
    " #Create customer value score\n",
    "df_imputed['customer_value_score'] = (\n",
    "    df_imputed['tenure_months'] * 0.3 + \n",
    "    df_imputed['num_products'] * 20 + \n",
    "    df_imputed['account_balance'] * 0.01\n",
    ")\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(df_imputed[['age_group', 'income_bracket', 'balance_to_income_ratio', 'customer_value_score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68f64461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 9: ENCODING CATEGORICAL VARIABLES\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 9: ENCODING CATEGORICAL VARIABLES\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 9: ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_encoded = df_imputed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4cc1ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9.1 Label Encoding for binary/ordinal variables...\n",
      "Gender mapping: {'Female': np.int64(0), 'Male': np.int64(1), 'Other': np.int64(2)}\n"
     ]
    }
   ],
   "source": [
    "# 9.1 Label Encoding for ordinal variables\n",
    "print(\"\\n9.1 Label Encoding for binary/ordinal variables...\")\n",
    "le_gender = LabelEncoder()\n",
    "df_encoded['gender_encoded'] = le_gender.fit_transform(df_encoded['gender'])\n",
    "print(f\"Gender mapping: {dict(zip(le_gender.classes_, le_gender.transform(le_gender.classes_)))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ba45219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9.2 One-Hot Encoding for nominal variables...\n",
      "Columns after encoding: 21\n",
      "\n",
      "New column names:\n",
      "['balance_to_income_ratio', 'customer_value_score', 'gender_encoded', 'location_Suburban', 'location_Urban', 'age_group_Middle', 'age_group_Senior', 'age_group_Elderly', 'income_bracket_Medium', 'income_bracket_High', 'income_bracket_Very High']\n"
     ]
    }
   ],
   "source": [
    "# 9.2 One-Hot Encoding for nominal variables\n",
    "print(\"\\n9.2 One-Hot Encoding for nominal variables...\")\n",
    "df_encoded = pd.get_dummies(df_encoded, \n",
    "                            columns=['location', 'age_group', 'income_bracket'], \n",
    "                            prefix=['location', 'age_group', 'income_bracket'],\n",
    "                            drop_first=True)\n",
    "\n",
    "print(f\"Columns after encoding: {df_encoded.shape[1]}\")\n",
    "print(\"\\nNew column names:\")\n",
    "print([col for col in df_encoded.columns if '_' in col and col not in df_clean.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbad78db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 10: FEATURE SCALING\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================\n",
    "# STEP 10: FEATURE SCALING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 10: FEATURE SCALING\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ef7597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10.1 Standardization (Z-score normalization)...\n",
      "Statistics after scaling:\n",
      "                age        income  account_balance  tenure_months  \\\n",
      "count  1.000000e+03  1.000000e+03     1.000000e+03   1.000000e+03   \n",
      "mean  -1.172396e-16 -1.172396e-16    -1.740830e-16   2.486900e-17   \n",
      "std    1.000500e+00  1.000500e+00     1.000500e+00   1.000500e+00   \n",
      "min   -1.811365e+00 -2.657681e+00    -1.778853e+00  -1.749184e+00   \n",
      "25%   -7.944435e-01 -6.075887e-01    -7.406484e-01  -8.287953e-01   \n",
      "50%    0.000000e+00 -2.867988e-04     3.562387e-03  -2.716632e-02   \n",
      "75%    8.439292e-01  6.099393e-01     6.944437e-01   8.338426e-01   \n",
      "max    1.634868e+00  2.664099e+00     2.847082e+00   1.754231e+00   \n",
      "\n",
      "       credit_score  balance_to_income_ratio  customer_value_score  \n",
      "count  1.000000e+03             1.000000e+03          1.000000e+03  \n",
      "mean   4.423129e-16            -1.421085e-17          2.131628e-17  \n",
      "std    1.000500e+00             1.000500e+00          1.000500e+00  \n",
      "min   -1.754400e+00            -2.028775e+01         -2.622539e+00  \n",
      "25%   -8.769286e-01            -1.034000e-01         -6.954747e-01  \n",
      "50%    7.138242e-16            -3.100292e-02         -2.556706e-02  \n",
      "75%    9.141173e-01             5.981820e-02          7.070582e-01  \n",
      "max    1.692696e+00             2.097870e+01          3.025958e+00  \n"
     ]
    }
   ],
   "source": [
    "# Select numerical features to scale\n",
    "features_to_scale = ['age', 'income', 'account_balance', 'tenure_months', \n",
    "                     'credit_score', 'balance_to_income_ratio', 'customer_value_score']\n",
    "\n",
    "print(\"\\n10.1 Standardization (Z-score normalization)...\")\n",
    "scaler = StandardScaler()\n",
    "df_scaled = df_encoded.copy()\n",
    "df_scaled[features_to_scale] = scaler.fit_transform(df_encoded[features_to_scale])\n",
    "\n",
    "print(\"Statistics after scaling:\")\n",
    "print(df_scaled[features_to_scale].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Create the scaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # Features to normalize\n",
    "# features_to_scale = ['age', 'income', 'account_balance', 'tenure_months', \n",
    "#                      'credit_score', 'balance_to_income_ratio', 'customer_value_score']\n",
    "\n",
    "# # Apply normalization\n",
    "# df_normalized = df_encoded.copy()\n",
    "# df_normalized[features_to_scale] = scaler.fit_transform(df_encoded[features_to_scale])\n",
    "\n",
    "# print(\"Statistics after normalization:\")\n",
    "# print(df_normalized[features_to_scale].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e43aaaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 11: TRAIN-TEST SPLIT\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================\n",
    "# STEP 11: TRAIN-TEST SPLIT\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 11: TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfa4c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df_scaled.drop(['customer_id', 'gender', 'churned'], axis=1, errors='ignore')\n",
    "y = df_scaled['churned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd85f6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature columns: ['age', 'income', 'account_balance', 'tenure_months', 'num_products', 'credit_score', 'customer_service_calls', 'balance_to_income_ratio', 'customer_value_score', 'gender_encoded', 'location_Suburban', 'location_Urban', 'age_group_Middle', 'age_group_Senior', 'age_group_Elderly', 'income_bracket_Medium', 'income_bracket_High', 'income_bracket_Very High']\n",
      "Number of features: 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFeature columns: {X.columns.tolist()}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "013311ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 800 samples\n",
      "Test set size: 200 samples\n",
      "\n",
      "Class distribution in training set:\n",
      "churned\n",
      "0    0.7325\n",
      "1    0.2675\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution in test set:\n",
      "churned\n",
      "0    0.735\n",
      "1    0.265\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5eb4092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 12: MODEL TRAINING\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 12: MODEL TRAINING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 12: MODEL TRAINING\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4131ff73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12.1 Training Random Forest Classifier...\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n12.1 Training Random Forest Classifier...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "695b99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13.1 Accuracy Score:\n",
      "Accuracy: 0.7050\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\n13.1 Accuracy Score:\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4edb6838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13.2 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83       147\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.36      0.48      0.41       200\n",
      "weighted avg       0.53      0.70      0.61       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n13.2 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "254c04cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13.3 Confusion Matrix:\n",
      "[[141   6]\n",
      " [ 53   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n13.3 Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8587d628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13.4 Feature Importance:\n",
      "                   feature  importance\n",
      "5             credit_score    0.131513\n",
      "3            tenure_months    0.128013\n",
      "1                   income    0.115270\n",
      "8     customer_value_score    0.115097\n",
      "7  balance_to_income_ratio    0.104510\n",
      "2          account_balance    0.098171\n",
      "0                      age    0.091722\n",
      "6   customer_service_calls    0.066190\n",
      "4             num_products    0.035265\n",
      "9           gender_encoded    0.025950\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n13.4 Feature Importance:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feature_importance.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97016270",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfeature_importances_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e5cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9819d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
